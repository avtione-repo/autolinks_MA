\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\reset@newl@bel
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{Sutton1998introduction}
\citation{Sutton1998introduction}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\newlabel{sec:introduction}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Reinforcement Learning Basics}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Basic Setup}{2}}
\citation{Sutton1998introduction}
\citation{Sutton1998introduction}
\citation{baier2007learning}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Reinforcement learning diagram showing an agent's interaction with its environment \cite  {Sutton1998introduction}.}}{3}}
\newlabel{rl}{{1}{3}}
\citation{Sutton1998introduction}
\citation{Sutton1998introduction}
\citation{Sutton1998introduction}
\citation{Sutton1998introduction}
\citation{Sutton1998introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Q-Value functions}{4}}
\newlabel{eq2}{{1}{4}}
\newlabel{eq3}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Finding optimal policies}{4}}
\citation{Thomaz2006reinforcement}
\citation{thomaz2005real}
\citation{knox2012reinforcement}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Q learning}}{5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces SARSA}}{5}}
\citation{Taylor2014reinforcement}
\citation{cruz2015interactive}
\@writefile{toc}{\contentsline {section}{\numberline {3}RL with Interactive Feedback}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Approaches for Human Advising}{6}}
\newlabel{sec:model:subsec:latex}{{3.1}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Approaches for Agent Advising}{6}}
\newlabel{sec:model:subsec:tables}{{3.2}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Implementation}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Description of the implemented algorithm}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Parameter Optimizations for different scenarios}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Discussion and Results}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{6}}
\newlabel{sec:concl}{{5}{6}}
\bibstyle{plain}
\bibdata{bib}
\bibcite{baier2007learning}{1}
\bibcite{cruz2015interactive}{2}
\bibcite{knox2012reinforcement}{3}
\bibcite{Sutton1998introduction}{4}
\bibcite{Taylor2014reinforcement}{5}
\bibcite{Thomaz2006reinforcement}{6}
\bibcite{thomaz2005real}{7}
\@writefile{toc}{\contentsline {section}{Bibliography}{7}}
